{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from tsfresh.examples import load_robot_execution_failures\n",
    "from tsfresh import extract_features, select_features\n",
    "import optuna\n",
    "\n",
    "from common import EP\n",
    "from models import *\n",
    "\n",
    "import types\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('../feats/df_train.pkl')\n",
    "df_test = pd.read_pickle('../feats/df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['y'].apply(lambda x:  int(x) if x<15 else 15)\n",
    "group = df_train['season'].values\n",
    "group[np.where(group==17)[0]] = 1\n",
    "df_train['group'] = group\n",
    "df_train = df_train.drop(columns=['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = df_train.drop(columns=['y','index','group','label']).copy()\n",
    "test_X.index = df_train['index']\n",
    "test_y = df_train['y'].copy()\n",
    "test_y.index = df_train['index']\n",
    "tsfresh_columns = select_features(test_X, test_y).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1071"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tsfresh_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = df_train.columns.drop(['index','y','label','group']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_path(base_dir, param):\n",
    "#     if base_dir == None:\n",
    "#         return None\n",
    "#     fold_path = base_dir + '/' + ','.join(\"{!s}={!r}\".format(key,val) for (key,val) in param.items())\n",
    "#     if not os.path.exists(fold_path):\n",
    "#         os.makedirs(fold_path)\n",
    "#     return fold_path\n",
    "\n",
    "# class KerasMLPRegressor(object):\n",
    "    \n",
    "#     def __init__(self, batch, input_dim, hidden_layer_sizes, activation, dropout, solver, metric, lr, sgd_momentum, sgd_decay, base_save_dir, alias):\n",
    "        \n",
    "#         self.batch = batch\n",
    "#         self.input_dim = input_dim\n",
    "#         self.hidden_layer_sizes = hidden_layer_sizes\n",
    "#         self.activation = activation\n",
    "#         self.solver = solver\n",
    "#         self.metric = metric\n",
    "#         self.dropout = dropout\n",
    "#         self.lr = lr\n",
    "#         self.sgd_momentum = sgd_momentum\n",
    "#         self.sgd_decay = sgd_decay\n",
    "        \n",
    "#         self.regressor = self.build_graph(input_dim, hidden_layer_sizes, activation, dropout)\n",
    "#         self.compile_graph(self.regressor, solver, metric, lr, sgd_momentum, sgd_decay)\n",
    "        \n",
    "#         self.alias = alias\n",
    "#         self.base_save_dir = base_save_dir\n",
    "#         if (self.alias==None) & (self.base_save_dir==None):\n",
    "#             self.chkpt = None\n",
    "#         else:\n",
    "#             self.chkpt = os.path.join(base_save_dir,'{}.hdf5'.format(alias))\n",
    "\n",
    "#         return\n",
    "    \n",
    "#     def build_graph(self, input_dim, hidden_layer_sizes, activation, dropout):\n",
    "    \n",
    "#         print(input_dim,hidden_layer_sizes,activation,dropout)\n",
    "#         i = Input(shape = (input_dim,))\n",
    "#         x = Dense(hidden_layer_sizes[0], activation=activation)(i)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = Dropout(dropout)(x)\n",
    "#         for units in hidden_layer_sizes[1:-1]:\n",
    "#             x = Dense(units, activation=activation)(x)\n",
    "#             x = BatchNormalization()(x)\n",
    "#             x = Dropout(dropout)(x)\n",
    "#         x = Dense(units, activation=activation)(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         y = Dense(1)(x)\n",
    "#         regressor = Model(inputs = [i], outputs = [y])\n",
    "#         return regressor\n",
    "    \n",
    "#     def compile_graph(self, model, solver, metric, lr, momentum, decay):\n",
    "#         if solver=='adam':\n",
    "#             optimizer = optimizers.adam(lr=lr)\n",
    "#         elif solver=='sgd':\n",
    "#             optimizer = optimizers.SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True)\n",
    "#         model.compile(optimizer=optimizer, loss=metric)\n",
    "#         return\n",
    "    \n",
    "#     def fit(self, X_train, y_train, eval_set, versbose=1, epochs=200, early_stopping_rounds=20):\n",
    "        \n",
    "# #         reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=early_stopping_rounds//4, min_lr=self.lr*1e-2)\n",
    "#         es_cb = EarlyStopping(monitor='val_loss', patience=early_stopping_rounds, verbose=1, mode='auto')\n",
    "#         cp_cb = ModelCheckpoint(filepath = self.chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# #         his_train = self.regressor.fit_generator( generator =  train_gen, epochs = epochs,  verbose = 1,  validation_data = validation, callbacks = [cp_cb])\n",
    "#         his_train = self.regressor.fit( X_train, y_train, epochs = epochs,  verbose = 1,  validation_data = eval_set[0], callbacks = [cp_cb,es_cb])\n",
    "#         df_train_his = pd.DataFrame(his_train.history)\n",
    "        \n",
    "# #         df_train_his = pd.DataFrame()\n",
    "# #         prev_val_loss = 999999\n",
    "# #         for i in np.arange(epochs):\n",
    "# #             his_train = self.regressor.fit( X_train, y_train, epochs = 1,  verbose = versbose,  batch_size = self.batch,  validation_data = validation,  callbacks = [])\n",
    "# #             df_train_his_i = pd.DataFrame(his_train.history)\n",
    "# #             df_train_his_i['epochs'] = i+1\n",
    "# #             df_train_his = pd.concat([df_train_his, df_train_his_i], axis=0)\n",
    "# #             if (df_train_his_i.val_loss.values[0] < prev_val_loss) & (self.chkpt!=None):\n",
    "# #                 prev_val_loss = df_train_his_i.val_loss.values[0]\n",
    "# #                 self.regressor.save_weights(self.chkpt)\n",
    "                \n",
    "#         df_train_his.to_csv(self.base_save_dir + '/train_his.csv', index=True)\n",
    "            \n",
    "#         return df_train_his\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         return self.regressor.predict(X)[:,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_param={\n",
    "    'input_dim':1071,\n",
    "    'hidden_layer_sizes':[4096,4096,4096,4096,2048,256,32],\n",
    "    'activation':'relu',\n",
    "    'dropout':.3,\n",
    "}\n",
    "base_save_dir = create_path('KerasMLPRegressor', path_param)\n",
    "param={\n",
    "    'algorithm': {\n",
    "        'cls': 'KerasMLPRegressor',\n",
    "        'fit': {\n",
    "            'versbose':10, \n",
    "            'epochs':100, \n",
    "            'early_stopping_rounds':20,\n",
    "        },\n",
    "        'init': {\n",
    "            'batch':32, \n",
    "            'solver':'adam', \n",
    "            'metric':'mean_absolute_error', \n",
    "            'lr':.0001, \n",
    "            'sgd_momentum':.9, \n",
    "            'sgd_decay':0.00001,\n",
    "            'base_save_dir':base_save_dir, \n",
    "            'alias':'kerasmlp',\n",
    "            **path_param\n",
    "        }\n",
    "    },\n",
    "    'columns': tsfresh_columns,\n",
    "    'feature_importance': {\n",
    "        'is_output': False,\n",
    "        'permutation_feature_importance': False,\n",
    "        'permutation_random_state': 1\n",
    "    },\n",
    "    'kfold': {\n",
    "        'n_splits': 8,\n",
    "        'random_state': 1985,\n",
    "        'shuffle': True,\n",
    "        'type': 'stratified'\n",
    "    },\n",
    "    'scaler': {\n",
    "        'cls': 'StandardScaler'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrial = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.97339, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.97339 to 2.01919, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.01919 to 1.93348, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.93348 to 1.90592, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.90592 to 1.85838, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.85838\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.85838 to 1.77955, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.77955 to 1.70114, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.70114\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.70114 to 1.68276, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.68276\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.68276 to 1.60006, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.60006 to 1.57939, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.57939 to 1.57691, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.57691 to 1.47641, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.47641\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.47641\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.47641 to 1.41958, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.41958 to 1.37222, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.37222\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.37222 to 1.34809, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.34809 to 1.30479, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.30479\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.30479\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.30479\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.30479\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.30479\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.30479 to 1.23482, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.23482\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.23482\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.23482 to 1.15414, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.15414\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.15414\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.15414 to 1.13777, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.13777 to 1.10183, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.10183\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.10183\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.10183 to 1.04670, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.04670\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.04670\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.04670\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.04670\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.04670 to 1.03334, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.03334\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.03334\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.03334 to 1.03163, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.03163 to 1.01883, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.01883\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.01883 to 1.00329, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.00329 to 0.94519, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.94519 to 0.93574, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.93574\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.93574\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.93574\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.93574\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.93574 to 0.92023, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.92023\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.92023\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.92023\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.92023\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.92023 to 0.89933, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.89933\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.89933\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.89933 to 0.85808, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.85808\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.85808\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.85808\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00068: val_loss improved from 0.85808 to 0.77683, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.77683\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.77683 to 0.77226, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.77226\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.77226\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.77226 to 0.75750, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.75750\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.75750 to 0.72783, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.72783\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.72783\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.72783\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.72783\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.72783\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.72783\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.72783 to 0.72087, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.72087 to 0.69685, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.69685\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.69685\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.69685\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.69685\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.69685\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.69685\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.69685\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.90354, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.90354 to 2.09567, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.09567 to 2.00457, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.00457 to 1.93571, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.93571 to 1.83884, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.83884\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.83884 to 1.80967, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.80967 to 1.74099, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.74099 to 1.68931, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.68931\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.68931\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.68931 to 1.61366, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.61366\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.61366 to 1.61177, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.61177 to 1.50214, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.50214\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.50214\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.50214 to 1.49378, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.49378\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.49378 to 1.44717, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.44717\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.44717 to 1.36856, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.36856\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.36856\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.36856\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.36856\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.36856 to 1.32465, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.32465 to 1.28551, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.28551 to 1.26554, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.26554\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.26554\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.26554 to 1.16765, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.16765\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.16765\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.16765\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.16765\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.16765\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.16765\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.16765 to 1.14309, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.14309\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.14309\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.14309 to 1.13627, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.13627 to 1.13060, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00044: val_loss improved from 1.13060 to 1.04020, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.04020\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.04020\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.04020\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.04020 to 1.03674, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.03674\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.03674\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.03674\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.03674 to 1.02846, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.02846 to 0.98803, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.98803\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.98803\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.98803\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.98803 to 0.96309, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.96309\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.96309\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.96309 to 0.95094, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.95094 to 0.92853, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.92853 to 0.88636, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.88636\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.88636\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.88636 to 0.88125, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.88125\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.88125\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.88125\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.88125\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.88125 to 0.84079, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.84079\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.84079 to 0.83504, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.83504 to 0.81621, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.81621 to 0.79833, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.79833\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.79833\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.79833\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.79833\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.79833\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.79833 to 0.79042, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.79042\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.79042\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.79042\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.79042 to 0.75399, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.75399\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.75399\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.75399 to 0.73130, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.73130\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.73130\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.73130\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.21937, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.21937 to 1.97566, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.97566 to 1.97052, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.97052 to 1.89013, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.89013 to 1.88875, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.88875 to 1.87973, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.87973 to 1.74653, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.74653 to 1.73077, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.73077\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.73077 to 1.67601, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.67601 to 1.61225, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.61225\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.61225 to 1.56233, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.56233\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.56233 to 1.49144, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.49144\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017: val_loss did not improve from 1.49144\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.49144 to 1.42384, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.42384 to 1.39736, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.39736\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.39736\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.39736 to 1.38703, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.38703 to 1.38338, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.38338 to 1.28007, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.28007\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.28007 to 1.24469, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.24469\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.24469\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.24469\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.24469\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.24469\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.24469\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.24469\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.24469 to 1.16752, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.16752\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.16752 to 1.15350, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.15350\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.15350\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.15350\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.15350\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.15350 to 1.12658, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.12658\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.12658 to 1.02765, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.02765\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.02765 to 0.99780, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.99780 to 0.99316, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.99316\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.99316 to 0.98789, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.98789\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.98789\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.98789 to 0.94498, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.94498\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.94498 to 0.88863, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.88863\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.88863\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.88863\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.88863 to 0.87569, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.87569\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.87569\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.87569\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.87569\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.87569\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.87569\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.87569 to 0.81947, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.81947\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.81947\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.81947\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.81947\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.81947\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.81947 to 0.80341, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.80341\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.80341\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.80341\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.80341\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.80341\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.80341 to 0.76654, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.76654\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.76654\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.76654\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.76654\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.76654\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.76654 to 0.75161, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.75161 to 0.73999, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.73999 to 0.71053, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.71053\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.71053\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.71053\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.71053\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.71053\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.71053\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.71053\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.71053\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.63274, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002: val_loss improved from 2.63274 to 2.12129, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.12129 to 2.00867, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.00867 to 1.94645, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.94645 to 1.93632, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.93632 to 1.89515, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.89515 to 1.85677, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.85677 to 1.77472, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.77472\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.77472\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.77472 to 1.74712, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.74712 to 1.64928, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.64928 to 1.63253, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.63253\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.63253\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.63253 to 1.58008, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp.hdf5\n"
     ]
    }
   ],
   "source": [
    "# run one try\n",
    "df_his,  df_feature_importances, df_valid_pred, df_test_pred =  EP.process(df_train, param, df_test = df_test, trial=mytrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpu_p36)",
   "language": "python",
   "name": "conda_tensorflow_gpu_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
