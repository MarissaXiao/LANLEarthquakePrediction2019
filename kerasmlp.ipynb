{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/.conda/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from tsfresh.examples import load_robot_execution_failures\n",
    "from tsfresh import extract_features, select_features\n",
    "import optuna\n",
    "\n",
    "from common import EP\n",
    "from models import *\n",
    "\n",
    "import types\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('../feats/df_train.pkl')\n",
    "df_test = pd.read_pickle('../feats/df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['y'].apply(lambda x:  int(x) if x<15 else 15)\n",
    "group = df_train['season'].values\n",
    "group[np.where(group==17)[0]] = 1\n",
    "df_train['group'] = group\n",
    "df_train = df_train.drop(columns=['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = df_train.drop(columns=['y','index','group','label']).copy()\n",
    "test_X.index = df_train['index']\n",
    "test_y = df_train['y'].copy()\n",
    "test_y.index = df_train['index']\n",
    "tsfresh_columns = select_features(test_X, test_y).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1071"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tsfresh_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_columns = df_train.columns.drop(['index','y','label','group']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_path(base_dir, param):\n",
    "#     if base_dir == None:\n",
    "#         return None\n",
    "#     fold_path = base_dir + '/' + ','.join(\"{!s}={!r}\".format(key,val) for (key,val) in param.items())\n",
    "#     if not os.path.exists(fold_path):\n",
    "#         os.makedirs(fold_path)\n",
    "#     return fold_path\n",
    "\n",
    "# class KerasMLPRegressor(object):\n",
    "    \n",
    "#     def __init__(self, batch, input_dim, hidden_layer_sizes, activation, dropout, solver, metric, lr, sgd_momentum, sgd_decay, base_save_dir, alias):\n",
    "        \n",
    "#         self.batch = batch\n",
    "#         self.input_dim = input_dim\n",
    "#         self.hidden_layer_sizes = hidden_layer_sizes\n",
    "#         self.activation = activation\n",
    "#         self.solver = solver\n",
    "#         self.metric = metric\n",
    "#         self.dropout = dropout\n",
    "#         self.lr = lr\n",
    "#         self.sgd_momentum = sgd_momentum\n",
    "#         self.sgd_decay = sgd_decay\n",
    "        \n",
    "#         self.regressor = self.build_graph(input_dim, hidden_layer_sizes, activation, dropout)\n",
    "#         self.compile_graph(self.regressor, solver, metric, lr, sgd_momentum, sgd_decay)\n",
    "        \n",
    "#         self.alias = alias\n",
    "#         self.base_save_dir = base_save_dir\n",
    "#         if (self.alias==None) & (self.base_save_dir==None):\n",
    "#             self.chkpt = None\n",
    "#         else:\n",
    "#             self.chkpt = os.path.join(base_save_dir,'{}.hdf5'.format(alias))\n",
    "\n",
    "#         return\n",
    "    \n",
    "#     def build_graph(self, input_dim, hidden_layer_sizes, activation, dropout):\n",
    "    \n",
    "#         print(input_dim,hidden_layer_sizes,activation,dropout)\n",
    "#         i = Input(shape = (input_dim,))\n",
    "#         x = Dense(hidden_layer_sizes[0], activation=activation)(i)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = Dropout(dropout)(x)\n",
    "#         for units in hidden_layer_sizes[1:-1]:\n",
    "#             x = Dense(units, activation=activation)(x)\n",
    "#             x = BatchNormalization()(x)\n",
    "#             x = Dropout(dropout)(x)\n",
    "#         x = Dense(units, activation=activation)(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         y = Dense(1)(x)\n",
    "#         regressor = Model(inputs = [i], outputs = [y])\n",
    "#         return regressor\n",
    "    \n",
    "#     def compile_graph(self, model, solver, metric, lr, momentum, decay):\n",
    "#         if solver=='adam':\n",
    "#             optimizer = optimizers.adam(lr=lr)\n",
    "#         elif solver=='sgd':\n",
    "#             optimizer = optimizers.SGD(lr=lr, decay=decay, momentum=momentum, nesterov=True)\n",
    "#         model.compile(optimizer=optimizer, loss=metric)\n",
    "#         return\n",
    "    \n",
    "#     def fit(self, X_train, y_train, eval_set, versbose=1, epochs=200, early_stopping_rounds=20):\n",
    "        \n",
    "# #         reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=early_stopping_rounds//4, min_lr=self.lr*1e-2)\n",
    "#         es_cb = EarlyStopping(monitor='val_loss', patience=early_stopping_rounds, verbose=1, mode='auto')\n",
    "#         cp_cb = ModelCheckpoint(filepath = self.chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "# #         his_train = self.regressor.fit_generator( generator =  train_gen, epochs = epochs,  verbose = 1,  validation_data = validation, callbacks = [cp_cb])\n",
    "#         his_train = self.regressor.fit( X_train, y_train, epochs = epochs,  verbose = 1,  validation_data = eval_set[0], callbacks = [cp_cb,es_cb])\n",
    "#         df_train_his = pd.DataFrame(his_train.history)\n",
    "        \n",
    "# #         df_train_his = pd.DataFrame()\n",
    "# #         prev_val_loss = 999999\n",
    "# #         for i in np.arange(epochs):\n",
    "# #             his_train = self.regressor.fit( X_train, y_train, epochs = 1,  verbose = versbose,  batch_size = self.batch,  validation_data = validation,  callbacks = [])\n",
    "# #             df_train_his_i = pd.DataFrame(his_train.history)\n",
    "# #             df_train_his_i['epochs'] = i+1\n",
    "# #             df_train_his = pd.concat([df_train_his, df_train_his_i], axis=0)\n",
    "# #             if (df_train_his_i.val_loss.values[0] < prev_val_loss) & (self.chkpt!=None):\n",
    "# #                 prev_val_loss = df_train_his_i.val_loss.values[0]\n",
    "# #                 self.regressor.save_weights(self.chkpt)\n",
    "                \n",
    "#         df_train_his.to_csv(self.base_save_dir + '/train_his.csv', index=True)\n",
    "            \n",
    "#         return df_train_his\n",
    "    \n",
    "#     def predict(self, X):\n",
    "#         return self.regressor.predict(X)[:,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_param={\n",
    "    'input_dim':1071,\n",
    "    'hidden_layer_sizes':[4096,4096,4096,4096,2048,256,32],\n",
    "    'activation':'relu',\n",
    "    'dropout':.3,\n",
    "}\n",
    "base_save_dir = create_path('KerasMLPRegressor', path_param)\n",
    "param={\n",
    "    'algorithm': {\n",
    "        'cls': 'KerasMLPRegressor',\n",
    "        'fit': {\n",
    "            'versbose':10, \n",
    "            'epochs':100, \n",
    "            'early_stopping_rounds':20,\n",
    "        },\n",
    "        'init': {\n",
    "            'batch':32, \n",
    "            'solver':'adam', \n",
    "            'metric':'mean_absolute_error', \n",
    "            'lr':.0001, \n",
    "            'sgd_momentum':.9, \n",
    "            'sgd_decay':0.00001,\n",
    "            'base_save_dir':base_save_dir, \n",
    "            'alias':'kerasmlp',\n",
    "            **path_param\n",
    "        }\n",
    "    },\n",
    "    'columns': tsfresh_columns,\n",
    "    'feature_importance': {\n",
    "        'is_output': False,\n",
    "        'permutation_feature_importance': False,\n",
    "        'permutation_random_state': 1\n",
    "    },\n",
    "    'kfold': {\n",
    "        'n_splits': 8,\n",
    "        'random_state': 1985,\n",
    "        'shuffle': True,\n",
    "        'type': 'stratified'\n",
    "    },\n",
    "    'scaler': {\n",
    "        'cls': 'StandardScaler'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\";  \n",
    " \n",
    "# # Do other imports now...\n",
    "# import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mytrial = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.02191, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.02191 to 2.04974, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.04974 to 1.95623, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.95623 to 1.87247, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.87247\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.87247 to 1.79281, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.79281\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.79281 to 1.76658, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.76658 to 1.74296, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.74296 to 1.68267, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.68267 to 1.56467, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.56467\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.56467\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.56467 to 1.52885, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.52885\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.52885 to 1.43765, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.43765\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.43765\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.43765\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.43765\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.43765\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.43765 to 1.41040, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.41040\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.41040\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.41040 to 1.33491, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.33491\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.33491 to 1.26533, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.26533\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.26533 to 1.24822, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.24822\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.24822 to 1.19468, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.19468\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.19468 to 1.13467, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.13467 to 1.13396, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.13396\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.13396\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.13396 to 1.12656, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.12656 to 1.12144, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.12144 to 1.10198, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.10198\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.10198 to 1.07272, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.07272\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.07272\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.07272\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.07272 to 1.03504, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.03504\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.03504 to 1.00771, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.00771 to 1.00088, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.00088 to 0.98301, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.98301\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.98301\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.98301\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.98301\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.98301 to 0.97464, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.97464\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.97464\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.97464 to 0.92848, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.92848\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.92848\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.92848 to 0.92168, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.92168 to 0.88643, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.88643\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.88643\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.88643\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.88643\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00066: val_loss did not improve from 0.88643\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.88643 to 0.82722, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.82722\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.82722\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.82722\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.82722 to 0.77823, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.77823\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.77823 to 0.76704, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.76704\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.76704 to 0.73042, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_0.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.73042\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.05373, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.05373 to 2.07599, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.07599 to 1.98537, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.98537 to 1.90290, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.90290 to 1.88271, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.88271 to 1.83080, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.83080 to 1.75859, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.75859 to 1.74745, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.74745\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.74745 to 1.65055, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.65055 to 1.62875, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.62875\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.62875 to 1.59892, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.59892 to 1.58344, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.58344\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.58344 to 1.50397, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.50397\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.50397\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.50397 to 1.44553, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.44553 to 1.43865, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.43865\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.43865 to 1.37388, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.37388\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.37388 to 1.37248, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.37248\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.37248 to 1.32998, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.32998\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.32998 to 1.30419, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.30419\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.30419 to 1.20905, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.20905 to 1.19847, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.19847\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.19847\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.19847\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.19847 to 1.18895, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.18895 to 1.14724, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.14724\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00038: val_loss improved from 1.14724 to 1.11507, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.11507\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.11507\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.11507\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.11507 to 1.08646, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.08646\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.08646\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.08646\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.08646\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.08646 to 1.02843, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.02843\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.02843\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.02843 to 0.98218, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.98218\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.98218\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.98218\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.98218 to 0.96272, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.96272\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.96272\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.96272\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.96272\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.96272\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.96272 to 0.93512, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.93512\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.93512\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.93512\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.93512 to 0.92564, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.92564\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.92564\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.92564 to 0.86358, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.86358\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.86358 to 0.84271, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.84271 to 0.80936, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.80936 to 0.80866, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.80866\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.80866\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.80866 to 0.80309, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.80309\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.80309 to 0.79903, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.79903\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.79903\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.79903\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.79903\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.79903 to 0.77743, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.77743\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.77743 to 0.75629, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.75629\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.75629 to 0.74186, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.74186 to 0.72791, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.72791\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.72791\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.72791\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.72791\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.72791 to 0.70512, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_1.hdf5\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.70512\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.89956, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.89956 to 2.00046, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.00046 to 1.98024, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.98024 to 1.97890, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.97890 to 1.84540, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.84540 to 1.76924, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.76924\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.76924\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.76924 to 1.72714, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.72714 to 1.68153, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.68153\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.68153 to 1.60755, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: val_loss improved from 1.60755 to 1.57874, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.57874 to 1.55638, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.55638 to 1.48913, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.48913 to 1.48166, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.48166\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.48166\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.48166\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.48166 to 1.43273, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.43273\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.43273 to 1.40550, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.40550 to 1.31160, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.31160\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.31160\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.31160 to 1.28152, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.28152\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.28152\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.28152\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.28152 to 1.25798, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.25798 to 1.18481, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.18481\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.18481\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.18481\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.18481 to 1.16470, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.16470 to 1.11649, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.11649\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.11649\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.11649\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.11649\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.11649\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.11649\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.11649 to 1.11093, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.11093\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.11093 to 1.07355, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.07355 to 1.06453, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.06453 to 1.00020, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.00020\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.00020\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.00020\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.00020 to 0.96145, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.96145\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.96145 to 0.95402, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.95402\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.95402\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.95402\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.95402\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.95402 to 0.91258, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.91258\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.91258\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.91258\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.91258\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.91258\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.91258\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.91258 to 0.89433, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.89433 to 0.88393, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.88393\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.88393\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.88393 to 0.86645, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.86645 to 0.84978, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.84978\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.84978\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.84978\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.84978\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.84978\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.84978 to 0.80398, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.80398\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.80398\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.80398\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.80398 to 0.79779, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.79779 to 0.77004, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.77004\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00091: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.77004\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.77004 to 0.74075, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.74075\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.74075\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.74075\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.74075\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.74075\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.74075\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.74075 to 0.71083, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_2.hdf5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.85141, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.85141 to 2.00259, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.00259 to 2.00050, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.00050 to 1.90010, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.90010\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.90010 to 1.85362, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.85362 to 1.80132, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.80132\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.80132 to 1.74867, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.74867\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.74867 to 1.66736, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.66736 to 1.63616, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.63616 to 1.57550, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.57550 to 1.56780, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.56780 to 1.56007, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.56007\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.56007 to 1.50276, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.50276\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.50276\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.50276 to 1.43886, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.43886 to 1.34942, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.34942\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.34942\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.88029\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.88029\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.88029 to 0.82932, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.82932\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.82932\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.82932\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.82932 to 0.82746, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.82746\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.82746 to 0.82475, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.82475 to 0.79988, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.79988\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.79988\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.79988\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.79988 to 0.79628, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.79628 to 0.73237, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.73237\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.73237 to 0.72165, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_3.hdf5\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.72165\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.70693, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.70693 to 2.03018, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.03018 to 1.91742, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.91742 to 1.91042, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.91042\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: val_loss improved from 1.91042 to 1.88884, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.88884 to 1.82122, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.82122 to 1.81627, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.81627 to 1.71964, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.71964 to 1.65805, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.65805 to 1.61689, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.61689 to 1.60764, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.60764 to 1.51338, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.51338\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.51338 to 1.48965, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.48965 to 1.45419, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.45419\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.45419\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.45419 to 1.39256, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.39256\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.39256 to 1.32817, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.32817\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.32817\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.32817\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.32817\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.32817\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.32817 to 1.29412, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.29412\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.29412 to 1.24351, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.24351\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.24351\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.24351 to 1.19809, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.19809 to 1.18511, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.18511 to 1.15813, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.15813 to 1.12673, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.12673\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.12673\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.12673 to 1.08193, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.08193\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.08193\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.08193\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.08193\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.08193 to 1.08074, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.08074\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.08074 to 1.01895, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.01895\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.01895\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.01895 to 1.00335, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.00335\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.00335 to 0.99800, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.99800 to 0.97138, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.97138\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.97138\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.97138\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.97138\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.97138\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.97138 to 0.93944, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.93944\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.93944 to 0.93891, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.93891 to 0.91535, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.91535 to 0.89983, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.89983\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.89983\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.89983\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.89983\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.89983 to 0.86443, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.86443\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.86443 to 0.85776, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.85776\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.85776\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00071: val_loss did not improve from 0.85776\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.85776\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.85776\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.85776\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.85776 to 0.81475, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.81475\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.81475\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.81475\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.81475\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.81475\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.81475 to 0.81049, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.81049\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.81049\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.81049\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.81049 to 0.75760, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.75760\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.75760\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.75760\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.75760 to 0.74715, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.74715\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.74715\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.74715\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.74715\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.74715\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.74715\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.74715 to 0.71739, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.71739 to 0.70744, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_4.hdf5\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.70744\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.70744\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.70744\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.95934, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.95934 to 1.98730, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.98730 to 1.92531, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.92531 to 1.90526, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.90526 to 1.83578, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.83578\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.83578\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.83578 to 1.76563, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.76563 to 1.73676, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.73676 to 1.68123, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.68123 to 1.65639, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.65639\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.65639\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.65639 to 1.60566, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.60566 to 1.56571, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.56571 to 1.55212, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.55212 to 1.52632, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.52632 to 1.52399, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.52399 to 1.49860, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.49860 to 1.45422, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.45422 to 1.38476, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.38476\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.38476\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.38476 to 1.33676, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.33676\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.33676\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.33676\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.33676 to 1.28966, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.28966\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.28966\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.28966\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.28966\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.28966\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.28966 to 1.21685, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.21685\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.21685\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.21685\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.21685 to 1.13564, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.13564\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.13564 to 1.10405, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.10405\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.10405\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00043: val_loss did not improve from 1.10405\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.10405\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.10405 to 1.09294, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.09294 to 1.05915, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.05915 to 1.03227, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.03227\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.03227\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.03227\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.03227 to 1.02230, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.02230 to 0.99441, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.99441 to 0.98454, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.98454\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.98454\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.98454\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.98454 to 0.96884, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.96884 to 0.96428, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.96428 to 0.94435, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.94435 to 0.90823, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.90823 to 0.90376, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.90376\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.90376\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.90376\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.90376\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.90376 to 0.87784, saving model to KerasMLPRegressor/input_dim=1071,hidden_layer_sizes=[4096, 4096, 4096, 4096, 2048, 256, 32],activation='relu',dropout=0.3/kerasmlp_5.hdf5\n"
     ]
    }
   ],
   "source": [
    "# run one try\n",
    "df_his,  df_feature_importances, df_valid_pred, df_test_pred =  EP.process(df_train, param, df_test = df_test, trial=mytrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
