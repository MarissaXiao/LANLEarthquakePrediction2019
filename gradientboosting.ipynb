{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "from tsfresh.examples import load_robot_execution_failures\n",
    "from tsfresh import extract_features, select_features\n",
    "import optuna\n",
    "\n",
    "from common import EP\n",
    "\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('../feats/df_train.pkl')\n",
    "df_test = pd.read_pickle('../feats/df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['y'].apply(lambda x:  int(x) if x<15 else 15)\n",
    "group = df_train['season'].values\n",
    "group[np.where(group==17)[0]] = 1\n",
    "df_train['group'] = group\n",
    "df_train = df_train.drop(columns=['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = df_train.drop(columns=['y','index','group','label']).copy()\n",
    "test_X.index = df_train['index']\n",
    "test_y = df_train['y'].copy()\n",
    "test_y.index = df_train['index']\n",
    "tsfresh_columns = select_features(test_X, test_y).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = df_train.columns.drop(['index','y','label','group']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mytrial = []\n",
    "mytrial = list(pd.read_pickle('../trial/gradientboosting.pkl').T.to_dict().values())\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "len(mytrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param={'columns': ['q25_roll_std_100',\n",
    "  'spkt_welch_density__coeff_3',\n",
    "  'abs_q01_4',\n",
    "  'abs_q25_5',\n",
    "  'q05_roll_std_1000',\n",
    "  'median__roll_std',\n",
    "  'iqr_6',\n",
    "  'spkt_welch_densitycoeff_2',\n",
    "  'q05_roll_std_100',\n",
    "  'q05_2',\n",
    "  'abs_q75_7',\n",
    "  \"change_quantiles{'ql': 0.2, 'qh': 0.8, 'isabs': False, 'f_agg': 'var'}\",\n",
    "  \"value_count{'value': -1}\",\n",
    "  'abs_q95_2',\n",
    "  'MA_1000MA_std_mean_7',\n",
    "  '5000smoothness_std_',\n",
    "  '5000quantile25peak_to_average_power_ratio_',\n",
    "  'FFT_Mag_25q0',\n",
    "  '5000skewness_max_',\n",
    "  'q05_5',\n",
    "  'max_to_min_5',\n",
    "  \"autocorrelation{'lag': 5}\",\n",
    "  'abs_q05_2',\n",
    "  'min__roll_std',\n",
    "  '5000peak_peak_amp_max_',\n",
    "  'max_to_min_diff_5',\n",
    "  '5000form_factor_quantile75',\n",
    "  'iqr',\n",
    "  'kurt_7',\n",
    "  'spkt_welch_density__coeff_4',\n",
    "  \"number_peaks{'n': 3}\",\n",
    "  'spkt_welch_density__coeff_42',\n",
    "  'fft_coefficientcoeff_20__attr_\"abs\"',\n",
    "  '5000quantile05median_',\n",
    "  'abs_max_2',\n",
    "  \"number_peaks{'n': 1}\",\n",
    "  'abs_max_8',\n",
    "  \"number_peaks{'n': 5}\",\n",
    "  'spkt_welch_density__coeff_17',\n",
    "  'abs_max_3',\n",
    "  '4th_peak_psd',\n",
    "  \"autocorrelation{'lag': 4}\",\n",
    "  '5000min_quantile05',\n",
    "  '5000kurtosis_mean_',\n",
    "  'min_9',\n",
    "  'ave10_6',\n",
    "  'spkt_welch_density__coeff_57',\n",
    "  'abs_max_7',\n",
    "  'agg_autocorrelationf_agg_\"mean\"__maxlag_40',\n",
    "  'spkt_welch_density__coeff_31',\n",
    "  'kurt_3',\n",
    "  '5000skewness_mean_',\n",
    "  '5000kurtosis_quantile75',\n",
    "  'abs_q95_6',\n",
    "  'spkt_welch_densitycoeff_8',\n",
    "  'abs_min_5',\n",
    "  'med_4',\n",
    "  'abs_q01_7',\n",
    "  'spkt_welch_density__coeff_64',\n",
    "  'abs_min_3',\n",
    "  'fft_coefficientcoeff_19__attr_\"abs\"',\n",
    "  'fft_coefficientcoeff_62__attr_\"abs\"',\n",
    "  'spkt_welch_density__coeff_99',\n",
    "  'partial_autocorrelationlag_1',\n",
    "  'fft_coefficientcoeff_56__attr_\"angle\"',\n",
    "  'fft_coefficientcoeff_6__attr_\"abs\"',\n",
    "  'iqr_8',\n",
    "  'abs_q05_1',\n",
    "  'abs_max_6',\n",
    "  'fft_coefficientcoeff_36__attr_\"abs\"'],\n",
    " 'kfold': {'n_splits': 3,\n",
    "  'random_state': 1985,\n",
    "  'shuffle': True,\n",
    "  'type': 'stratified'},\n",
    " 'scaler': {'cls': 'StandardScaler'},\n",
    " 'algorithm': {'cls': 'GradientBoostingRegressor',\n",
    "  'init': {'max_depth': 3,\n",
    "   'learning_rate': 0.04018024140881379,\n",
    "   'n_estimators': 253,\n",
    "   'subsample': 0.6846361552509973,\n",
    "   'alpha': 0.9990262087522855,\n",
    "   'random_state': 2784},\n",
    "  'fit': {}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one try\n",
    "df_his,  df_feature_importances, df_valid_pred, df_test_pred =  EP.process(df_train, param, df_test = df_test, trial=mytrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check feature_importances\n",
    "# df_feature_importances = df_trial.loc[14]['df_feature_importances']\n",
    "# if type(df_feature_importances)==pd.DataFrame:\n",
    "#     sorted_columns = EP.evaluate(df_feature_importances, key='average_model_weight')\n",
    "# else:\n",
    "#     sorted_columns = df_trial.loc[14]['param']['columns']\n",
    "# df_feature_importances.sort_values(by=['average_permutation_weight'], ascending=False)\n",
    "# len(sorted_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mae_var</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mae_var</th>\n",
       "      <th>mae_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2019-05-16 11:03:43.728017</td>\n",
       "      <td>70</td>\n",
       "      <td>1.84528</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>1.906736</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.061456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      datetime  nfeatures  train_mae  train_mae_var   val_mae  \\\n",
       "220 2019-05-16 11:03:43.728017         70    1.84528        0.00002  1.906736   \n",
       "\n",
       "     val_mae_var  mae_diff  \n",
       "220     0.000234  0.061456  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial = pd.DataFrame(mytrial)\n",
    "#[(df_trial['mae_diff']<.05)].sort_values(by=['val_mae'], ascending=True)\n",
    "df_trial[['datetime','nfeatures', 'train_mae','train_mae_var','val_mae','val_mae_var','mae_diff']].tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-05-16 11:11:04,714] Finished a trial resulted in value: 1.1003866575630066. Current best value is 1.1003866575630066 with parameters: {'max_depth': 5, 'learning_rate': 0.2673759810262276, 'n_estimators': 455, 'subsample': 0.815126163788147, 'alpha': 0.5579249669410118, 'random_state': 3603}.\n",
      "[I 2019-05-16 11:12:10,862] Finished a trial resulted in value: 0.3637291200466947. Current best value is 0.3637291200466947 with parameters: {'max_depth': 4, 'learning_rate': 0.17193290826962068, 'n_estimators': 134, 'subsample': 0.7292935105100071, 'alpha': 0.6361955441244439, 'random_state': 9478}.\n",
      "[I 2019-05-16 11:14:32,771] Finished a trial resulted in value: 0.637563537069587. Current best value is 0.3637291200466947 with parameters: {'max_depth': 4, 'learning_rate': 0.17193290826962068, 'n_estimators': 134, 'subsample': 0.7292935105100071, 'alpha': 0.6361955441244439, 'random_state': 9478}.\n",
      "[I 2019-05-16 11:17:35,291] Finished a trial resulted in value: 0.5143052245062809. Current best value is 0.3637291200466947 with parameters: {'max_depth': 4, 'learning_rate': 0.17193290826962068, 'n_estimators': 134, 'subsample': 0.7292935105100071, 'alpha': 0.6361955441244439, 'random_state': 9478}.\n",
      "[I 2019-05-16 11:18:18,088] Finished a trial resulted in value: 0.17116499007016392. Current best value is 0.17116499007016392 with parameters: {'max_depth': 2, 'learning_rate': 0.22788467587709343, 'n_estimators': 200, 'subsample': 0.7099226624693894, 'alpha': 0.1260633569892408, 'random_state': 8718}.\n",
      "[I 2019-05-16 11:19:51,656] Finished a trial resulted in value: 0.31468614608201523. Current best value is 0.17116499007016392 with parameters: {'max_depth': 2, 'learning_rate': 0.22788467587709343, 'n_estimators': 200, 'subsample': 0.7099226624693894, 'alpha': 0.1260633569892408, 'random_state': 8718}.\n",
      "[I 2019-05-16 11:20:56,289] Finished a trial resulted in value: 0.0971386372578706. Current best value is 0.0971386372578706 with parameters: {'max_depth': 2, 'learning_rate': 0.07432781269493488, 'n_estimators': 272, 'subsample': 0.911700906139188, 'alpha': 0.6201772033928601, 'random_state': 3846}.\n",
      "[I 2019-05-16 11:23:42,368] Finished a trial resulted in value: 0.6577144018433237. Current best value is 0.0971386372578706 with parameters: {'max_depth': 2, 'learning_rate': 0.07432781269493488, 'n_estimators': 272, 'subsample': 0.911700906139188, 'alpha': 0.6201772033928601, 'random_state': 3846}.\n",
      "[I 2019-05-16 11:25:15,842] Finished a trial resulted in value: 0.6439000446332427. Current best value is 0.0971386372578706 with parameters: {'max_depth': 2, 'learning_rate': 0.07432781269493488, 'n_estimators': 272, 'subsample': 0.911700906139188, 'alpha': 0.6201772033928601, 'random_state': 3846}.\n",
      "[I 2019-05-16 11:26:02,173] Finished a trial resulted in value: 0.1667481368168387. Current best value is 0.0971386372578706 with parameters: {'max_depth': 2, 'learning_rate': 0.07432781269493488, 'n_estimators': 272, 'subsample': 0.911700906139188, 'alpha': 0.6201772033928601, 'random_state': 3846}.\n",
      "[I 2019-05-16 11:27:23,101] Finished a trial resulted in value: 0.051947329454146665. Current best value is 0.051947329454146665 with parameters: {'max_depth': 2, 'learning_rate': 0.02709694332385648, 'n_estimators': 325, 'subsample': 0.9989615789708036, 'alpha': 0.9776168908005336, 'random_state': 6398}.\n",
      "[I 2019-05-16 11:32:27,759] Finished a trial resulted in value: 0.3730572527855046. Current best value is 0.051947329454146665 with parameters: {'max_depth': 2, 'learning_rate': 0.02709694332385648, 'n_estimators': 325, 'subsample': 0.9989615789708036, 'alpha': 0.9776168908005336, 'random_state': 6398}.\n",
      "[I 2019-05-16 11:34:46,593] Finished a trial resulted in value: 0.31679620750236104. Current best value is 0.051947329454146665 with parameters: {'max_depth': 2, 'learning_rate': 0.02709694332385648, 'n_estimators': 325, 'subsample': 0.9989615789708036, 'alpha': 0.9776168908005336, 'random_state': 6398}.\n",
      "[I 2019-05-16 11:36:44,486] Finished a trial resulted in value: 0.03933910561150104. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 11:39:52,769] Finished a trial resulted in value: 0.09914569400317148. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 11:45:07,057] Finished a trial resulted in value: 0.7623224244772359. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 11:46:41,502] Finished a trial resulted in value: 0.10942895685388927. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 11:48:41,335] Finished a trial resulted in value: 0.04119973412879763. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 11:51:48,102] Finished a trial resulted in value: 0.6573045431278668. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 11:53:39,644] Finished a trial resulted in value: 0.2656317030983153. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 11:56:07,752] Finished a trial resulted in value: 0.5075047146725143. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 11:58:15,294] Finished a trial resulted in value: 0.2258972709476325. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:01:25,685] Finished a trial resulted in value: 0.25992573995522705. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:04:21,733] Finished a trial resulted in value: 0.31227059933734114. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:08:57,189] Finished a trial resulted in value: 0.9156268178974606. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:09:49,920] Finished a trial resulted in value: 0.2663762977288734. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-05-16 12:10:26,171] Finished a trial resulted in value: 0.2401239001531168. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:13:23,611] Finished a trial resulted in value: 0.2960989339604943. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:19:36,926] Finished a trial resulted in value: 1.4674707941630605. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:24:29,986] Finished a trial resulted in value: 0.7811414846532656. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:25:03,698] Finished a trial resulted in value: 0.08706504854171526. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:27:48,734] Finished a trial resulted in value: 0.06822474235729277. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:31:56,410] Finished a trial resulted in value: 0.6790766203577974. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:36:21,056] Finished a trial resulted in value: 0.9305057504739446. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:37:45,542] Finished a trial resulted in value: 0.3729118773157026. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:39:41,512] Finished a trial resulted in value: 0.2379161128205871. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:43:48,453] Finished a trial resulted in value: 0.7895584493872309. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:44:53,761] Finished a trial resulted in value: 0.05692045199054059. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:46:02,992] Finished a trial resulted in value: 0.24342559775580563. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:48:52,933] Finished a trial resulted in value: 0.5860135481226127. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:50:04,276] Finished a trial resulted in value: 0.09140795711877606. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:52:55,657] Finished a trial resulted in value: 0.7101071052081187. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:58:39,833] Finished a trial resulted in value: 0.7564832351994286. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 12:59:31,097] Finished a trial resulted in value: 0.2007724544307318. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:01:49,314] Finished a trial resulted in value: 0.6839468546814511. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:08:45,610] Finished a trial resulted in value: 1.3500915971709209. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:10:04,476] Finished a trial resulted in value: 0.06253465352173823. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:11:06,061] Finished a trial resulted in value: 0.15173193503897098. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:15:30,119] Finished a trial resulted in value: 0.8660675533432196. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:17:13,231] Finished a trial resulted in value: 0.45413197009341805. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:18:00,256] Finished a trial resulted in value: 0.16580058793472455. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:19:07,215] Finished a trial resulted in value: 0.1039062927617106. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-05-16 13:20:48,282] Finished a trial resulted in value: 0.11189077221138567. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:23:20,190] Finished a trial resulted in value: 0.7247767989869182. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:24:20,486] Finished a trial resulted in value: 0.1259890815636178. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:26:30,744] Finished a trial resulted in value: 0.4284329804177467. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:28:10,376] Finished a trial resulted in value: 0.39000876090445064. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:32:58,847] Finished a trial resulted in value: 0.8078802755482691. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:34:25,268] Finished a trial resulted in value: 0.3002665456328006. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:38:28,106] Finished a trial resulted in value: 0.5688436040505757. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:40:21,494] Finished a trial resulted in value: 0.4125078167350281. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:43:47,499] Finished a trial resulted in value: 0.43049671261199735. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:45:08,482] Finished a trial resulted in value: 0.2732679934347335. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:49:06,220] Finished a trial resulted in value: 0.159716293886382. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:50:37,722] Finished a trial resulted in value: 0.14600936493230549. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:52:00,914] Finished a trial resulted in value: 0.05251702896430754. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:53:05,014] Finished a trial resulted in value: 0.06685343482918864. Current best value is 0.03933910561150104 with parameters: {'max_depth': 2, 'learning_rate': 0.01277049228577442, 'n_estimators': 500, 'subsample': 0.9397787290669495, 'alpha': 0.8199914338254779, 'random_state': 2571}.\n",
      "[I 2019-05-16 13:54:18,982] Finished a trial resulted in value: 0.023914848770287954. Current best value is 0.023914848770287954 with parameters: {'max_depth': 2, 'learning_rate': 0.011110233458343974, 'n_estimators': 285, 'subsample': 0.9798395560156627, 'alpha': 0.8051440718493055, 'random_state': 8532}.\n",
      "[I 2019-05-16 13:56:09,815] Finished a trial resulted in value: 0.18519463714678858. Current best value is 0.023914848770287954 with parameters: {'max_depth': 2, 'learning_rate': 0.011110233458343974, 'n_estimators': 285, 'subsample': 0.9798395560156627, 'alpha': 0.8051440718493055, 'random_state': 8532}.\n",
      "[I 2019-05-16 13:57:12,602] Finished a trial resulted in value: 0.12259869056802537. Current best value is 0.023914848770287954 with parameters: {'max_depth': 2, 'learning_rate': 0.011110233458343974, 'n_estimators': 285, 'subsample': 0.9798395560156627, 'alpha': 0.8051440718493055, 'random_state': 8532}.\n",
      "[I 2019-05-16 13:58:28,237] Finished a trial resulted in value: 0.02358115970860336. Current best value is 0.02358115970860336 with parameters: {'max_depth': 2, 'learning_rate': 0.010156358859071932, 'n_estimators': 311, 'subsample': 0.977567161793835, 'alpha': 0.7198650049938701, 'random_state': 8603}.\n",
      "[I 2019-05-16 13:59:38,586] Finished a trial resulted in value: 0.02472658184174129. Current best value is 0.02358115970860336 with parameters: {'max_depth': 2, 'learning_rate': 0.010156358859071932, 'n_estimators': 311, 'subsample': 0.977567161793835, 'alpha': 0.7198650049938701, 'random_state': 8603}.\n",
      "[I 2019-05-16 14:01:17,232] Finished a trial resulted in value: 0.18301078901173717. Current best value is 0.02358115970860336 with parameters: {'max_depth': 2, 'learning_rate': 0.010156358859071932, 'n_estimators': 311, 'subsample': 0.977567161793835, 'alpha': 0.7198650049938701, 'random_state': 8603}.\n",
      "[I 2019-05-16 14:02:06,601] Finished a trial resulted in value: 0.05732113544576591. Current best value is 0.02358115970860336 with parameters: {'max_depth': 2, 'learning_rate': 0.010156358859071932, 'n_estimators': 311, 'subsample': 0.977567161793835, 'alpha': 0.7198650049938701, 'random_state': 8603}.\n",
      "[I 2019-05-16 14:03:11,099] Finished a trial resulted in value: 0.022932735860323395. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:04:17,087] Finished a trial resulted in value: 0.07602190838191171. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:05:18,740] Finished a trial resulted in value: 0.10253015116803973. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:06:05,942] Finished a trial resulted in value: 0.06700979219136122. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-05-16 14:07:04,955] Finished a trial resulted in value: 0.190059554753343. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:08:01,309] Finished a trial resulted in value: 0.1126128170177638. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:10:05,246] Finished a trial resulted in value: 0.05120814159760063. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:11:01,894] Finished a trial resulted in value: 0.052598439211273794. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:12:09,044] Finished a trial resulted in value: 0.05927000822725848. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:12:57,555] Finished a trial resulted in value: 0.08994332919815339. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:15:44,993] Finished a trial resulted in value: 0.458929964429574. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:16:23,826] Finished a trial resulted in value: 0.0723654079558777. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:17:25,999] Finished a trial resulted in value: 0.15445856258760296. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:18:18,838] Finished a trial resulted in value: 0.20395510349996246. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:19:43,522] Finished a trial resulted in value: 0.059929318321563896. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:20:45,952] Finished a trial resulted in value: 0.11830103622072059. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:21:57,857] Finished a trial resulted in value: 0.3066178411620984. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:24:53,386] Finished a trial resulted in value: 0.6930593367532296. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:28:34,983] Finished a trial resulted in value: 1.1334859373000563. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:29:42,783] Finished a trial resulted in value: 0.13875899727662774. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:33:34,921] Finished a trial resulted in value: 1.316486393156181. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:34:48,114] Finished a trial resulted in value: 0.03635276391452296. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:36:56,754] Finished a trial resulted in value: 0.15385933576136485. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:37:51,699] Finished a trial resulted in value: 0.16827259567429428. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:39:19,701] Finished a trial resulted in value: 0.1608600658468617. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:42:09,203] Finished a trial resulted in value: 0.29785335665993334. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:46:51,046] Finished a trial resulted in value: 0.6144851065817346. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:48:21,438] Finished a trial resulted in value: 0.18694112310984815. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:49:22,084] Finished a trial resulted in value: 0.17070624040748883. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:49:57,148] Finished a trial resulted in value: 0.03661659834615418. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2019-05-16 14:52:30,086] Finished a trial resulted in value: 0.5107889122628924. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n",
      "[I 2019-05-16 14:53:50,022] Finished a trial resulted in value: 0.2677602112941815. Current best value is 0.022932735860323395 with parameters: {'max_depth': 2, 'learning_rate': 0.01032226388250946, 'n_estimators': 293, 'subsample': 0.7967808427773099, 'alpha': 0.5385476572038151, 'random_state': 8553}.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bc14c07c78be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     def _optimize_parallel(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Setting trial status as {}. {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-bc14c07c78be>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     38\u001b[0m     }\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdf_his\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdf_feature_importances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_valid_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_pred\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mEP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmytrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tune 220'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mval_mae_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_his\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mval_mae_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_his\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/wangzhaoxu/ep/LANLEarthquakePrediction2019/common.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(df_train, param, df_test, trial, remark, is_output_feature_importance)\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mX_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0my_valid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[1;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1194\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpu_p36/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###  tune hypterparameters\n",
    "def objective(trial):\n",
    "    \n",
    "    max_depth = trial.suggest_int('max_depth', 2, 6)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.01, 0.4)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100,500)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.6, 1.0)\n",
    "    alpha = trial.suggest_uniform('alpha', 0.00001, 1.0)\n",
    "    random_state = trial.suggest_int('random_state', 1, 9999)\n",
    "        \n",
    "    args={\n",
    "        'columns':param['columns'].copy(),\n",
    "        'kfold':{\n",
    "            'n_splits': 3,\n",
    "            'random_state': 1985,\n",
    "            'shuffle': True,\n",
    "            'type': 'stratified'\n",
    "        },\n",
    "        'scaler':{\n",
    "            'cls':'StandardScaler',\n",
    "        },\n",
    "        'algorithm':{\n",
    "            'cls':'GradientBoostingRegressor',\n",
    "            'init':{\n",
    "                \"max_depth\":max_depth,\n",
    "                \"learning_rate\":learning_rate,\n",
    "                \"n_estimators\":n_estimators,\n",
    "                \"subsample\":subsample,\n",
    "                \"alpha\":alpha,\n",
    "                \"random_state\":random_state,\n",
    "            },\n",
    "            'fit':{\n",
    "#                 'eval_metric':'mae',\n",
    "#                 'verbose':False,\n",
    "#                 'early_stopping_rounds':200,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    df_his,  df_feature_importances, df_valid_pred, df_test_pred =  EP.process(df_train, args, df_test = df_test, trial=mytrial, remark='tune 220')\n",
    "    val_mae_mean = np.mean(df_his.valid)\n",
    "    val_mae_var = np.var(df_his.valid)\n",
    "    train_mae_mean = np.mean(df_his.train)\n",
    "    train_mae_var = np.var(df_his.train)\n",
    "    \n",
    "    trial.set_user_attr('val_mae', val_mae_mean)\n",
    "    trial.set_user_attr('train_mae', train_mae_mean)\n",
    "    trial.set_user_attr('mae_diff', val_mae_mean-train_mae_mean)\n",
    "    trial.set_user_attr('val_mae_var', val_mae_var)\n",
    "\n",
    "    return np.abs(val_mae_mean - train_mae_mean)*val_mae_mean\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred = df_trial.loc[342]['df_test_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame()\n",
    "df_submit['time_to_failure'] = np.mean(df_test_pred.drop(columns=['index']).values, axis=1)\n",
    "df_submit['seg_id'] = df_test_pred['index']\n",
    "df_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = pd.DataFrame(mytrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>remark</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mae_var</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mae_var</th>\n",
       "      <th>mae_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2019-05-16 14:12:57.544171</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.891917</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.938320</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.046403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2019-05-16 12:50:04.270091</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.895138</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.942202</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.047064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>2019-05-16 12:25:03.693296</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.905621</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.950264</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.044643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2019-05-16 14:16:23.815368</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.914761</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.951837</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.037076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2019-05-16 14:04:17.076904</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.913728</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.952660</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.038932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2019-05-16 12:27:48.729137</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.929379</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.964114</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.034736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2019-05-16 14:06:05.931616</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.934922</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.968955</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.034033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2019-05-16 13:53:05.005114</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.936148</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.970082</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.033934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2019-05-16 14:12:09.034276</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.942505</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.972552</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.030047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2019-05-16 13:10:04.468930</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.942479</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.974155</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.031677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2019-05-16 14:02:06.591738</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.945673</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.974701</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.029028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2019-05-16 14:19:43.511218</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.947651</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.977950</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.030299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2019-05-16 12:44:53.755719</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.952954</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.981677</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.028723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2019-05-16 14:11:01.883394</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.957282</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.983796</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.026514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2019-05-16 14:10:05.235536</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.962561</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.988315</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.025755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2019-05-16 13:52:00.904835</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.962124</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.988534</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.026410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2019-05-16 11:27:23.098513</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.963069</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.989184</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.026115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2019-05-16 11:48:41.331219</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.985290</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>2.005830</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.020540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2019-05-16 11:36:44.483249</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.986702</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>2.006310</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2019-05-16 14:34:48.102304</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.992194</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>2.010277</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.018083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>2019-05-16 14:49:57.135309</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.997056</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>2.015226</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.018170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2019-05-16 13:59:38.576361</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>2.032511</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.044604</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.012094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>2019-05-16 13:58:28.227096</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>2.039559</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.051056</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.011497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2019-05-16 13:54:18.973423</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>2.039531</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.051190</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2019-05-16 14:03:11.089127</td>\n",
       "      <td>tune 220</td>\n",
       "      <td>70</td>\n",
       "      <td>2.041996</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.053165</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.011169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      datetime    remark  nfeatures  train_mae  train_mae_var  \\\n",
       "304 2019-05-16 14:12:57.544171  tune 220         70   1.891917       0.000012   \n",
       "261 2019-05-16 12:50:04.270091  tune 220         70   1.895138       0.000018   \n",
       "251 2019-05-16 12:25:03.693296  tune 220         70   1.905621       0.000009   \n",
       "306 2019-05-16 14:16:23.815368  tune 220         70   1.914761       0.000019   \n",
       "296 2019-05-16 14:04:17.076904  tune 220         70   1.913728       0.000019   \n",
       "252 2019-05-16 12:27:48.729137  tune 220         70   1.929379       0.000016   \n",
       "298 2019-05-16 14:06:05.931616  tune 220         70   1.934922       0.000015   \n",
       "287 2019-05-16 13:53:05.005114  tune 220         70   1.936148       0.000018   \n",
       "303 2019-05-16 14:12:09.034276  tune 220         70   1.942505       0.000016   \n",
       "267 2019-05-16 13:10:04.468930  tune 220         70   1.942479       0.000022   \n",
       "294 2019-05-16 14:02:06.591738  tune 220         70   1.945673       0.000022   \n",
       "309 2019-05-16 14:19:43.511218  tune 220         70   1.947651       0.000016   \n",
       "258 2019-05-16 12:44:53.755719  tune 220         70   1.952954       0.000017   \n",
       "302 2019-05-16 14:11:01.883394  tune 220         70   1.957282       0.000018   \n",
       "301 2019-05-16 14:10:05.235536  tune 220         70   1.962561       0.000022   \n",
       "286 2019-05-16 13:52:00.904835  tune 220         70   1.962124       0.000017   \n",
       "231 2019-05-16 11:27:23.098513  tune 220         70   1.963069       0.000018   \n",
       "238 2019-05-16 11:48:41.331219  tune 220         70   1.985290       0.000016   \n",
       "234 2019-05-16 11:36:44.483249  tune 220         70   1.986702       0.000022   \n",
       "316 2019-05-16 14:34:48.102304  tune 220         70   1.992194       0.000019   \n",
       "324 2019-05-16 14:49:57.135309  tune 220         70   1.997056       0.000018   \n",
       "292 2019-05-16 13:59:38.576361  tune 220         70   2.032511       0.000007   \n",
       "291 2019-05-16 13:58:28.227096  tune 220         70   2.039559       0.000005   \n",
       "288 2019-05-16 13:54:18.973423  tune 220         70   2.039531       0.000005   \n",
       "295 2019-05-16 14:03:11.089127  tune 220         70   2.041996       0.000005   \n",
       "\n",
       "      val_mae  val_mae_var  mae_diff  \n",
       "304  1.938320     0.000180  0.046403  \n",
       "261  1.942202     0.000159  0.047064  \n",
       "251  1.950264     0.000188  0.044643  \n",
       "306  1.951837     0.000144  0.037076  \n",
       "296  1.952660     0.000209  0.038932  \n",
       "252  1.964114     0.000176  0.034736  \n",
       "298  1.968955     0.000155  0.034033  \n",
       "287  1.970082     0.000166  0.033934  \n",
       "303  1.972552     0.000159  0.030047  \n",
       "267  1.974155     0.000162  0.031677  \n",
       "294  1.974701     0.000132  0.029028  \n",
       "309  1.977950     0.000174  0.030299  \n",
       "258  1.981677     0.000139  0.028723  \n",
       "302  1.983796     0.000148  0.026514  \n",
       "301  1.988315     0.000123  0.025755  \n",
       "286  1.988534     0.000135  0.026410  \n",
       "231  1.989184     0.000138  0.026115  \n",
       "238  2.005830     0.000115  0.020540  \n",
       "234  2.006310     0.000096  0.019608  \n",
       "316  2.010277     0.000095  0.018083  \n",
       "324  2.015226     0.000103  0.018170  \n",
       "292  2.044604     0.000089  0.012094  \n",
       "291  2.051056     0.000081  0.011497  \n",
       "288  2.051190     0.000079  0.011659  \n",
       "295  2.053165     0.000090  0.011169  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[df_trial['mae_diff']<.05].sort_values(by=['val_mae']) | (df_trial['remark']=='tune feats selected by group ')\n",
    "df_trial[(df_trial['remark']=='tune 220')&(df_trial['mae_diff']<.05)].sort_values(by=['val_mae'], ascending=True)[['datetime','remark', 'nfeatures', 'train_mae','train_mae_var','val_mae','val_mae_var','mae_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = pd.DataFrame(mytrial)\n",
    "df_trial.to_pickle('../trial/gradientboosting.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_gpu_p36)",
   "language": "python",
   "name": "conda_tensorflow_gpu_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
