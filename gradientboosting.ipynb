{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "from tsfresh.examples import load_robot_execution_failures\n",
    "from tsfresh import extract_features, select_features\n",
    "import optuna\n",
    "\n",
    "from common import EP\n",
    "\n",
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "   div#notebook-container    { width: 95%; }\n",
       "   div#menubar-container     { width: 65%; }\n",
       "   div#maintoolbar-container { width: 99%; }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "   div#notebook-container    { width: 95%; }\n",
    "   div#menubar-container     { width: 65%; }\n",
    "   div#maintoolbar-container { width: 99%; }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('feats/df_train.pkl')\n",
    "df_test = pd.read_pickle('feats/df_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['y'].apply(lambda x:  int(x) if x<15 else 15)\n",
    "group = df_train['season'].values\n",
    "group[np.where(group==17)[0]] = 1\n",
    "df_train['group'] = group\n",
    "df_train = df_train.drop(columns=['season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = df_train.drop(columns=['y','index','group','label']).copy()\n",
    "test_X.index = df_train['index']\n",
    "test_y = df_train['y'].copy()\n",
    "test_y.index = df_train['index']\n",
    "tsfresh_columns = select_features(test_X, test_y).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = df_train.columns.drop(['index','y','label','group']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mytrial = []\n",
    "mytrial = list(pd.read_pickle('trial/gradientboosting.pkl').T.to_dict().values())\n",
    "df_trial = pd.DataFrame(mytrial)\n",
    "len(mytrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param={\n",
    "    'algorithm': {\n",
    "        'cls': 'GradientBoostingRegressor',\n",
    "        'fit': {\n",
    "#             'early_stopping_rounds': 200,\n",
    "#             'eval_metric': 'mae',\n",
    "#             'verbose': False\n",
    "        },\n",
    "        'init': {\n",
    "#             'n_jobs':16,\n",
    "        }\n",
    "    },\n",
    "    'columns': tsfresh_columns,\n",
    "    'feature_importance': {\n",
    "        'is_output': True,\n",
    "        'permutation_feature_importance': True,\n",
    "        'permutation_random_state': 1\n",
    "    },\n",
    "    'kfold': {\n",
    "        'n_splits': 8,\n",
    "        'random_state': 1985,\n",
    "        'shuffle': True,\n",
    "        'type': 'group'\n",
    "    },\n",
    "    'scaler': {\n",
    "        'cls': 'StandardScaler'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one try\n",
    "df_his,  df_feature_importances, df_valid_pred, df_test_pred =  EP.process(df_train, param, df_test = None, trial=mytrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check feature_importances\n",
    "df_feature_importances = df_trial.loc[14]['df_feature_importances']\n",
    "if type(df_feature_importances)==pd.DataFrame:\n",
    "    sorted_columns = EP.evaluate(df_feature_importances, key='average_model_weight')\n",
    "else:\n",
    "    sorted_columns = df_trial.loc[14]['param']['columns']\n",
    "# df_feature_importances.sort_values(by=['average_permutation_weight'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['columns']=sorted_columns[:-10]\n",
    "#  select features by permutation_weight\n",
    "EP.select_features_(df_train, param, mytrial, nfeats_best=25, nfeats_removed_per_try=10, key='average_permutation_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mae_var</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mae_var</th>\n",
       "      <th>mae_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-10 10:08:45.942462</td>\n",
       "      <td>1071</td>\n",
       "      <td>1.818027</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>2.195905</td>\n",
       "      <td>0.527265</td>\n",
       "      <td>0.377878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-10 12:36:44.746797</td>\n",
       "      <td>200</td>\n",
       "      <td>1.819021</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>2.184827</td>\n",
       "      <td>0.523375</td>\n",
       "      <td>0.365805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-10 12:44:53.047447</td>\n",
       "      <td>190</td>\n",
       "      <td>1.820537</td>\n",
       "      <td>0.010106</td>\n",
       "      <td>2.179309</td>\n",
       "      <td>0.525266</td>\n",
       "      <td>0.358772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-10 12:52:49.016791</td>\n",
       "      <td>180</td>\n",
       "      <td>1.821202</td>\n",
       "      <td>0.010218</td>\n",
       "      <td>2.174044</td>\n",
       "      <td>0.530444</td>\n",
       "      <td>0.352842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-10 13:00:23.427527</td>\n",
       "      <td>170</td>\n",
       "      <td>1.822041</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>2.171204</td>\n",
       "      <td>0.531807</td>\n",
       "      <td>0.349163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-05-10 13:07:32.021287</td>\n",
       "      <td>160</td>\n",
       "      <td>1.826642</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>2.168563</td>\n",
       "      <td>0.541657</td>\n",
       "      <td>0.341921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-05-10 13:14:10.965752</td>\n",
       "      <td>150</td>\n",
       "      <td>1.830268</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>2.162702</td>\n",
       "      <td>0.531846</td>\n",
       "      <td>0.332434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-05-10 13:20:35.009869</td>\n",
       "      <td>140</td>\n",
       "      <td>1.834635</td>\n",
       "      <td>0.010421</td>\n",
       "      <td>2.145930</td>\n",
       "      <td>0.539925</td>\n",
       "      <td>0.311295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-05-10 13:26:21.571473</td>\n",
       "      <td>130</td>\n",
       "      <td>1.835565</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>2.147050</td>\n",
       "      <td>0.537258</td>\n",
       "      <td>0.311484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-05-10 13:31:45.137073</td>\n",
       "      <td>120</td>\n",
       "      <td>1.838652</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>2.141269</td>\n",
       "      <td>0.548358</td>\n",
       "      <td>0.302617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-05-10 13:36:39.507164</td>\n",
       "      <td>110</td>\n",
       "      <td>1.840209</td>\n",
       "      <td>0.010659</td>\n",
       "      <td>2.142945</td>\n",
       "      <td>0.540927</td>\n",
       "      <td>0.302736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-05-10 13:41:08.706703</td>\n",
       "      <td>100</td>\n",
       "      <td>1.841247</td>\n",
       "      <td>0.010977</td>\n",
       "      <td>2.143406</td>\n",
       "      <td>0.541002</td>\n",
       "      <td>0.302159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-05-10 13:44:59.481662</td>\n",
       "      <td>90</td>\n",
       "      <td>1.841775</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>2.141702</td>\n",
       "      <td>0.544291</td>\n",
       "      <td>0.299928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-05-10 13:48:21.770255</td>\n",
       "      <td>80</td>\n",
       "      <td>1.843837</td>\n",
       "      <td>0.010639</td>\n",
       "      <td>2.139495</td>\n",
       "      <td>0.544775</td>\n",
       "      <td>0.295658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-05-10 13:51:11.930220</td>\n",
       "      <td>70</td>\n",
       "      <td>1.843117</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>2.136263</td>\n",
       "      <td>0.541989</td>\n",
       "      <td>0.293146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-05-11 13:43:21.903034</td>\n",
       "      <td>60</td>\n",
       "      <td>1.843517</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>2.139622</td>\n",
       "      <td>0.542715</td>\n",
       "      <td>0.296106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-05-11 13:44:49.404702</td>\n",
       "      <td>50</td>\n",
       "      <td>1.843331</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>2.141989</td>\n",
       "      <td>0.540953</td>\n",
       "      <td>0.298658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-05-11 13:45:59.898172</td>\n",
       "      <td>40</td>\n",
       "      <td>1.850178</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>2.142847</td>\n",
       "      <td>0.540499</td>\n",
       "      <td>0.292669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-05-11 13:46:52.102302</td>\n",
       "      <td>30</td>\n",
       "      <td>1.853911</td>\n",
       "      <td>0.010675</td>\n",
       "      <td>2.147953</td>\n",
       "      <td>0.539084</td>\n",
       "      <td>0.294041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-05-11 13:47:25.365496</td>\n",
       "      <td>20</td>\n",
       "      <td>1.869091</td>\n",
       "      <td>0.011106</td>\n",
       "      <td>2.149785</td>\n",
       "      <td>0.533560</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     datetime  nfeatures  train_mae  train_mae_var   val_mae  \\\n",
       "0  2019-05-10 10:08:45.942462       1071   1.818027       0.010086  2.195905   \n",
       "1  2019-05-10 12:36:44.746797        200   1.819021       0.009948  2.184827   \n",
       "2  2019-05-10 12:44:53.047447        190   1.820537       0.010106  2.179309   \n",
       "3  2019-05-10 12:52:49.016791        180   1.821202       0.010218  2.174044   \n",
       "4  2019-05-10 13:00:23.427527        170   1.822041       0.009875  2.171204   \n",
       "5  2019-05-10 13:07:32.021287        160   1.826642       0.010263  2.168563   \n",
       "6  2019-05-10 13:14:10.965752        150   1.830268       0.010180  2.162702   \n",
       "7  2019-05-10 13:20:35.009869        140   1.834635       0.010421  2.145930   \n",
       "8  2019-05-10 13:26:21.571473        130   1.835565       0.010528  2.147050   \n",
       "9  2019-05-10 13:31:45.137073        120   1.838652       0.011059  2.141269   \n",
       "10 2019-05-10 13:36:39.507164        110   1.840209       0.010659  2.142945   \n",
       "11 2019-05-10 13:41:08.706703        100   1.841247       0.010977  2.143406   \n",
       "12 2019-05-10 13:44:59.481662         90   1.841775       0.010893  2.141702   \n",
       "13 2019-05-10 13:48:21.770255         80   1.843837       0.010639  2.139495   \n",
       "14 2019-05-10 13:51:11.930220         70   1.843117       0.010877  2.136263   \n",
       "15 2019-05-11 13:43:21.903034         60   1.843517       0.010664  2.139622   \n",
       "16 2019-05-11 13:44:49.404702         50   1.843331       0.010505  2.141989   \n",
       "17 2019-05-11 13:45:59.898172         40   1.850178       0.010648  2.142847   \n",
       "18 2019-05-11 13:46:52.102302         30   1.853911       0.010675  2.147953   \n",
       "19 2019-05-11 13:47:25.365496         20   1.869091       0.011106  2.149785   \n",
       "\n",
       "    val_mae_var  mae_diff  \n",
       "0      0.527265  0.377878  \n",
       "1      0.523375  0.365805  \n",
       "2      0.525266  0.358772  \n",
       "3      0.530444  0.352842  \n",
       "4      0.531807  0.349163  \n",
       "5      0.541657  0.341921  \n",
       "6      0.531846  0.332434  \n",
       "7      0.539925  0.311295  \n",
       "8      0.537258  0.311484  \n",
       "9      0.548358  0.302617  \n",
       "10     0.540927  0.302736  \n",
       "11     0.541002  0.302159  \n",
       "12     0.544291  0.299928  \n",
       "13     0.544775  0.295658  \n",
       "14     0.541989  0.293146  \n",
       "15     0.542715  0.296106  \n",
       "16     0.540953  0.298658  \n",
       "17     0.540499  0.292669  \n",
       "18     0.539084  0.294041  \n",
       "19     0.533560  0.280694  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial = pd.DataFrame(mytrial)\n",
    "#[(df_trial['mae_diff']<.05)].sort_values(by=['val_mae'], ascending=True)\n",
    "df_trial[['datetime','nfeatures', 'train_mae','train_mae_var','val_mae','val_mae_var','mae_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradientBoostingRegressor.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  tune hypterparameters\n",
    "def objective(trial):\n",
    "    \n",
    "    max_depth = trial.suggest_int('max_depth', 2, 6)\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.01, 0.4)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100,500)\n",
    "    subsample = trial.suggest_uniform('subsample', 0.6, 1.0)\n",
    "    alpha = trial.suggest_uniform('alpha', 0.00001, 1.0)\n",
    "    random_state = trial.suggest_int('random_state', 1, 9999)\n",
    "        \n",
    "    args={\n",
    "        'columns':df_trial.loc[14]['param']['columns'],\n",
    "        'kfold':{\n",
    "            'n_splits': 8,\n",
    "            'random_state': 1985,\n",
    "            'shuffle': True,\n",
    "            'type': 'stratified'\n",
    "        },\n",
    "        'scaler':{\n",
    "            'cls':'StandardScaler',\n",
    "        },\n",
    "        'algorithm':{\n",
    "            'cls':'GradientBoostingRegressor',\n",
    "            'init':{\n",
    "                \"max_depth\":max_depth,\n",
    "                \"learning_rate\":learning_rate,\n",
    "                \"n_estimators\":n_estimators,\n",
    "                \"subsample\":subsample,\n",
    "                \"alpha\":alpha,\n",
    "                \"random_state\":random_state,\n",
    "            },\n",
    "            'fit':{\n",
    "#                 'eval_metric':'mae',\n",
    "#                 'verbose':False,\n",
    "#                 'early_stopping_rounds':200,\n",
    "            },\n",
    "        },\n",
    "        'feature_importance':{\n",
    "            'is_output':False,\n",
    "            'permutation_feature_importance':False,\n",
    "            'permutation_random_state':1,\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    df_his,  df_feature_importances, df_valid_pred, df_test_pred =  EP.process(df_train, args, df_test = df_test, trial=mytrial, remark='tune feats selected by group')\n",
    "    val_mae_mean = np.mean(df_his.valid)\n",
    "    val_mae_var = np.var(df_his.valid)\n",
    "    train_mae_mean = np.mean(df_his.train)\n",
    "    train_mae_var = np.var(df_his.train)\n",
    "    \n",
    "    trial.set_user_attr('val_mae', val_mae_mean)\n",
    "    trial.set_user_attr('train_mae', train_mae_mean)\n",
    "    trial.set_user_attr('mae_diff', val_mae_mean-train_mae_mean)\n",
    "    trial.set_user_attr('val_mae_var', val_mae_var)\n",
    "\n",
    "    return np.abs(val_mae_mean - train_mae_mean)*val_mae_mean\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred = df_trial.loc[342]['df_test_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame()\n",
    "df_submit['time_to_failure'] = np.mean(df_test_pred.drop(columns=['index']).values, axis=1)\n",
    "df_submit['seg_id'] = df_test_pred['index']\n",
    "df_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = pd.DataFrame(mytrial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>remark</th>\n",
       "      <th>nfeatures</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>train_mae_var</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mae_var</th>\n",
       "      <th>mae_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2019-05-12 02:39:59.250350</td>\n",
       "      <td>tune feats selected by group</td>\n",
       "      <td>70</td>\n",
       "      <td>1.856828</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.903058</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.046231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2019-05-11 23:38:40.848657</td>\n",
       "      <td>tune feats selected by group</td>\n",
       "      <td>70</td>\n",
       "      <td>1.856952</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.906536</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.049584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2019-05-12 09:48:16.149257</td>\n",
       "      <td>tune feats selected by group</td>\n",
       "      <td>70</td>\n",
       "      <td>1.863059</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.910631</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.047571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-05-12 09:00:36.183418</td>\n",
       "      <td>tune feats selected by group</td>\n",
       "      <td>70</td>\n",
       "      <td>1.870492</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.914961</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.044469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2019-05-12 02:01:09.027461</td>\n",
       "      <td>tune feats selected by group</td>\n",
       "      <td>70</td>\n",
       "      <td>1.876371</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1.919986</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.043615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      datetime                        remark  nfeatures  \\\n",
       "83  2019-05-12 02:39:59.250350  tune feats selected by group         70   \n",
       "60  2019-05-11 23:38:40.848657  tune feats selected by group         70   \n",
       "183 2019-05-12 09:48:16.149257  tune feats selected by group         70   \n",
       "160 2019-05-12 09:00:36.183418  tune feats selected by group         70   \n",
       "79  2019-05-12 02:01:09.027461  tune feats selected by group         70   \n",
       "\n",
       "     train_mae  train_mae_var   val_mae  val_mae_var  mae_diff  \n",
       "83    1.856828       0.000006  1.903058     0.000434  0.046231  \n",
       "60    1.856952       0.000009  1.906536     0.000461  0.049584  \n",
       "183   1.863059       0.000003  1.910631     0.000432  0.047571  \n",
       "160   1.870492       0.000007  1.914961     0.000454  0.044469  \n",
       "79    1.876371       0.000008  1.919986     0.000399  0.043615  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[df_trial['mae_diff']<.05].sort_values(by=['val_mae']) | (df_trial['remark']=='tune feats selected by group ')\n",
    "df_trial[(df_trial['remark']=='tune feats selected by group')&(df_trial['mae_diff']<.05)].sort_values(by=['val_mae'], ascending=True)[['datetime','remark', 'nfeatures', 'train_mae','train_mae_var','val_mae','val_mae_var','mae_diff']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial.to_pickle('trial/gradientboosting.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['q25_roll_std_100',\n",
       "  'spkt_welch_density__coeff_3',\n",
       "  'abs_q01_4',\n",
       "  'abs_q25_5',\n",
       "  'q05_roll_std_1000',\n",
       "  'median__roll_std',\n",
       "  'iqr_6',\n",
       "  'spkt_welch_densitycoeff_2',\n",
       "  'q05_roll_std_100',\n",
       "  'q05_2',\n",
       "  'abs_q75_7',\n",
       "  \"change_quantiles{'ql': 0.2, 'qh': 0.8, 'isabs': False, 'f_agg': 'var'}\",\n",
       "  \"value_count{'value': -1}\",\n",
       "  'abs_q95_2',\n",
       "  'MA_1000MA_std_mean_7',\n",
       "  '5000smoothness_std_',\n",
       "  '5000quantile25peak_to_average_power_ratio_',\n",
       "  'FFT_Mag_25q0',\n",
       "  '5000skewness_max_',\n",
       "  'q05_5',\n",
       "  'max_to_min_5',\n",
       "  \"autocorrelation{'lag': 5}\",\n",
       "  'abs_q05_2',\n",
       "  'min__roll_std',\n",
       "  '5000peak_peak_amp_max_',\n",
       "  'max_to_min_diff_5',\n",
       "  '5000form_factor_quantile75',\n",
       "  'iqr',\n",
       "  'kurt_7',\n",
       "  'spkt_welch_density__coeff_4',\n",
       "  \"number_peaks{'n': 3}\",\n",
       "  'spkt_welch_density__coeff_42',\n",
       "  'fft_coefficientcoeff_20__attr_\"abs\"',\n",
       "  '5000quantile05median_',\n",
       "  'abs_max_2',\n",
       "  \"number_peaks{'n': 1}\",\n",
       "  'abs_max_8',\n",
       "  \"number_peaks{'n': 5}\",\n",
       "  'spkt_welch_density__coeff_17',\n",
       "  'abs_max_3',\n",
       "  '4th_peak_psd',\n",
       "  \"autocorrelation{'lag': 4}\",\n",
       "  '5000min_quantile05',\n",
       "  '5000kurtosis_mean_',\n",
       "  'min_9',\n",
       "  'ave10_6',\n",
       "  'spkt_welch_density__coeff_57',\n",
       "  'abs_max_7',\n",
       "  'agg_autocorrelationf_agg_\"mean\"__maxlag_40',\n",
       "  'spkt_welch_density__coeff_31',\n",
       "  'kurt_3',\n",
       "  '5000skewness_mean_',\n",
       "  '5000kurtosis_quantile75',\n",
       "  'abs_q95_6',\n",
       "  'spkt_welch_densitycoeff_8',\n",
       "  'abs_min_5',\n",
       "  'med_4',\n",
       "  'abs_q01_7',\n",
       "  'spkt_welch_density__coeff_64',\n",
       "  'abs_min_3',\n",
       "  'fft_coefficientcoeff_19__attr_\"abs\"',\n",
       "  'fft_coefficientcoeff_62__attr_\"abs\"',\n",
       "  'spkt_welch_density__coeff_99',\n",
       "  'partial_autocorrelationlag_1',\n",
       "  'fft_coefficientcoeff_56__attr_\"angle\"',\n",
       "  'fft_coefficientcoeff_6__attr_\"abs\"',\n",
       "  'iqr_8',\n",
       "  'abs_q05_1',\n",
       "  'abs_max_6',\n",
       "  'fft_coefficientcoeff_36__attr_\"abs\"'],\n",
       " 'kfold': {'n_splits': 8,\n",
       "  'random_state': 1985,\n",
       "  'shuffle': True,\n",
       "  'type': 'stratified'},\n",
       " 'scaler': {'cls': 'StandardScaler'},\n",
       " 'algorithm': {'cls': 'GradientBoostingRegressor',\n",
       "  'init': {'max_depth': 3,\n",
       "   'learning_rate': 0.04018024140881379,\n",
       "   'n_estimators': 253,\n",
       "   'subsample': 0.6846361552509973,\n",
       "   'alpha': 0.9990262087522855,\n",
       "   'random_state': 2784},\n",
       "  'fit': {}},\n",
       " 'feature_importance': {'is_output': False,\n",
       "  'permutation_feature_importance': False,\n",
       "  'permutation_random_state': 1}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial.loc[83]['param']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
